{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#### CALCULATING CLUSTERING STATS FOR POLLUTION_YEAR/grams #####\n",
    "################################################################\n",
    "\n",
    "# To do the analysis for *Capital_Amenity* change variable at 3 places where shown in code \n",
    "# and column names as to not overwrite existing data\n",
    "\n",
    "# Steps: \n",
    "# 1. Read in attributes as CSV \n",
    "# 2. Read in Camden boundaries as GEOJSON \n",
    "# 3. Transform attributes to GEOJSON \n",
    "# 4. Calculate KNN weights (same results if you use boundaries or attributes)\n",
    "\n",
    "\n",
    "# References:\n",
    "\n",
    "# Spatial analysis: \n",
    "# http://darribas.org/gds_scipy16/ipynb_md/04_esda.html\n",
    "# https://methods.sagepub.com/dataset/howtoguide/local-morans-i-berlin-districts-2018-python\n",
    "\n",
    "# Function to transform csv to geojson:\n",
    "# https://gis.stackexchange.com/questions/220997/pandas-to-geojson-multiples-points-features-with-python\n",
    "\n",
    "# KNN justification \n",
    "# https://towardsdatascience.com/a-simple-introduction-to-k-nearest-neighbors-algorithm-b3519ed98e\n",
    "\n",
    "# About Local Moran \n",
    "# https://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/h-how-spatial-autocorrelation-moran-s-i-spatial-st.htm\n",
    "\n",
    "\n",
    "\n",
    "import geojson\n",
    "import pandas \n",
    "import geopandas\n",
    "import pysal\n",
    "\n",
    "# Reading in attributes data (Camden Tree data)\n",
    "attributes_csv = pandas.read_csv('cleaned.csv')\n",
    "\n",
    "# Aggregating by ward \n",
    "attributes_agg = attributes_csv.groupby(['Ward_Name'], as_index=False).mean()\n",
    "\n",
    "# Function that will transform the csv pandas df to a geojson \n",
    "def data2geojson(df):\n",
    "    features = []\n",
    "    insert_features = lambda X: features.append(\n",
    "            geojson.Feature(geometry=geojson.Point((X[\"Lat\"],\n",
    "                                                    X[\"Lon\"])),\n",
    "                            properties=dict(Ward=X[\"Ward_Name\"],\n",
    "                                            Amenity_Value=X[\"Amenity_Value\"],\n",
    "                                            Pollution_Year_grams=X[\"Pollution_Year_grams\"])))\n",
    "    df.apply(insert_features, axis=1)\n",
    "    with open('attributes.geojson', 'w', encoding='utf8') as fp:\n",
    "        geojson.dump(geojson.FeatureCollection(features), fp, sort_keys=True, ensure_ascii=False)\n",
    "\n",
    "# Applying function \n",
    "data2geojson(attributes_agg)\n",
    "\n",
    "# Reading the attributes data as a geojson \n",
    "attributes_geojson = geopandas.read_file('attributes.geojson').to_crs(epsg = 27700)\n",
    "attributes_geojson\n",
    "\n",
    "# Reading in ward boundaries as a geojson \n",
    "neighbourhoods = geopandas.read_file('Camden Ward Boundary.geojson').to_crs(epsg = 27700) # geometry is a point \n",
    "\n",
    "# Calculating weights 'w' using the Camden Ward Boundary (NB: used with which has the centroid coords of each ward)\n",
    "w_pollution = pysal.weights.KNN.from_dataframe(neighbourhoods, k=5)\n",
    "\n",
    "# Calculating local moran statistics of proximity of *Pollution_Year_grams* using the weights \n",
    "local_morans = pysal.esda.moran.Moran_Local(attributes_geojson.Pollution_Year_grams, w_pollution, permutations=9999) \n",
    "\n",
    "# Checking what is significant \n",
    "Lag_pol = pysal.lag_spatial(w_pollution, attributes_geojson.Pollution_Year_grams) #*Change variable here*\n",
    "polperyr = attributes_geojson.Pollution_Year_grams.values #*Change variable here*\n",
    "\n",
    "sigs = polperyr[local_morans.p_sim <= .001]\n",
    "W_sigs = Lag_pol[local_morans.p_sim <= .001]\n",
    "insigs = polperyr[local_morans.p_sim > .001]\n",
    "W_insigs = Lag_pol[local_morans.p_sim > .001]\n",
    "\n",
    "# Calculating hotspots and coldspots \n",
    "sig = local_morans.p_sim < 0.05\n",
    "hotspots = local_morans.q==1 * sig\n",
    "hotspots.sum()\n",
    "coldspots = local_morans.q==3 * sig\n",
    "coldspots.sum()\n",
    "\n",
    "# Assigning local moran values, coldspots and hotspots to: \n",
    "# 1. the attributes df \n",
    "# 2. the Camden geojson boundary \n",
    "\n",
    "# 1.\n",
    "attributes_agg2 = attributes_agg.assign(pol_cl_value =local_morans.Is)\n",
    "attributes_agg2 = attributes_agg2.assign(pol_hotspots = local_morans.q==1 * sig)\n",
    "attributes_agg2 = attributes_agg2.assign(pol_coldspots = local_morans.q==3 * sig)\n",
    "\n",
    "# 2. \n",
    "attributes_geojson2 = attributes_geojson.assign(pol_cl_value =local_morans.Is)\n",
    "attributes_geojson2 = attributes_geojson2.assign(pol_hotspots = local_morans.q==1 * sig)\n",
    "attributes_geojson2 = attributes_geojson2.assign(pol_coldspots = local_morans.q==3 * sig)\n",
    "\n",
    "# Another statistic that can be used as the variable to be measured: z_sim\n",
    "# z_sim = standardized Is based on permutations\n",
    "# Assigning it to the two objects:\n",
    "# Breaks for mapping this variable: 2.58 - 1.96 - 1.65 - -1.65 - -1.96 - -2.58; \n",
    "\n",
    "attributes_agg2 = attributes_agg2.assign(pol_z_sim = local_morans.z_sim)\n",
    "attributes_geojson2 = attributes_geojson2.assign(pol_z_sim =local_morans.z_sim)\n",
    "\n",
    "# THE END: there are two objects with the same data: \n",
    "# attributes_agg2 - attributes data and clustering stats in pandas df format.\n",
    "# attributes_geojson2 - attributes data and clustering stats in GeoJSON.  \n",
    "\n",
    "# WHAT SHOULD BE MAPPED: \n",
    "# Either: coldspots and hotspots (but there are no coldspots, so the map might be ugly, only red and greyish)\n",
    "# Or pol_z_sim with breaks mentioned above, like this map can have a gradient (like the one made in R) \n",
    "# though I am not sure what the breaks mean, (they are from the GIS prac), I think they refer to the \n",
    "# 'intensity' of the clustering. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
